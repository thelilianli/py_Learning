{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your name: Lilian Li\n",
    "\n",
    "<pre> Enter your name here</pre>\n",
    "\n",
    "### Collaborators:\n",
    "\n",
    "<pre> Enter the name of the people you worked with if any</pre>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Markdown reference can be found here:\n",
    "    http://nestacms.com/docs/creating-content/markdown-cheat-sheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. Why would it be a problem if our training set and test set are the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre> If the training set and the test set is the same, the model will always be \"high performing\". This is not representative of the actual predictivity of the model accross the population. We would also not be able to identify the severity of overfitting.</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2 [OPTIONAL]. Explain step by step the process to select k in the k-nearest neighbor algorithm (pseudocode) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre> assuming we have labels in our data:\n",
    "        #let dataset be an n dimension dataset\n",
    "        #let metric be an already defined function to calculate distances for an n-dimensional data set\n",
    "        #let estimator be an already defined function to calculate the knn approximation for the label\n",
    "        #let label be the value/vector we are trying to predict using knn \n",
    "        \n",
    "        trainingset = random_subset(data, num = round(nrow(data)*0.80)) #assuming we want 80% of data to be training\n",
    "        testingset = remaining data\n",
    "        #further subsetting for cross validation can be done\n",
    "        #run trainingset through function to get k\n",
    "        \n",
    "        def select_k(data):\n",
    "            n = nrow(data)\n",
    "            #since rule of thumb k <= sqrt(n)\n",
    "            #initializing variables\n",
    "            best_k <- 1\n",
    "            min_error <- NaN\n",
    "            for i in 1 to sqrt(n):\n",
    "                run knn function (data, k = i, metric, estimator) to output predicted labels\n",
    "                compute min_squared_error between prediction and actual labels\n",
    "                if min_error == NaN or min_squared_error < min_error:\n",
    "                    best_k <- i\n",
    "                    min_error <- min_squared_error\n",
    "                else:\n",
    "                    Next i\n",
    "            return best_k    \n",
    "        \n",
    "        #Try knn using best_k with testingset?\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3. For the k-nearest regression. What happends when k = n. Where n is equal to the training size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre> average/mode of all the training data points label value is the final predicted value for any intput into the model </pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. Define a function that takes a 1-d numpy array, a parameter k, and a number p.\n",
    "The function returns an estimate equal to the mean of the closest k points to the number p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_neighbor(input_data, k, p):\n",
    "    \"\"\"Returns the k-neighbor estimate for p using data input_data.\n",
    "    \n",
    "    Keyword arguments:\n",
    "    input_data -- numpy array of all the data\n",
    "    k -- Number of k\n",
    "    p -- input values\n",
    "    \n",
    "    If you make assumptions please explain them in the comments. i.e. tie breaking strategy.\n",
    "    \"\"\"\n",
    "    \n",
    "    #YOUR CODE HERE\n",
    "    distance_data = np.array(np.absolute(input_data - p))\n",
    "    #print(distance_data)\n",
    "    \n",
    "    input_data_enhanced = pd.DataFrame({'data' : pd.Series(input_data, index=[x for x in range(0,15)]),\n",
    "                                        'dist' : pd.Series(distance_data, index=[x for x in range(0,15)])})\n",
    "    #print(input_data_enhanced.dtypes)\n",
    "    #print(input_data_enhanced.describe())\n",
    "    #print('original data and distances:')\n",
    "    #print(input_data_enhanced.sort_values('dist',ascending = True))\n",
    "    \n",
    "    #in case of ties: random - first instance selected\n",
    "    input_data_enhanced = input_data_enhanced.sort_values('dist',ascending = True)\n",
    "    #print(input_data_enhanced)\n",
    "    knn_mean = input_data_enhanced[:k]['data'].mean() \n",
    "    \n",
    "    return knn_mean\n",
    "    \n",
    "    #return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = np.array([1,3,4,5,7,8,11,12,13,15,19,24,25,29,40])\n",
    "print(k_neighbor(input_data=data, k=3, p=5)==((5+4+3)/3)) \n",
    "print(k_neighbor(input_data=data, k=2, p=15)==((15+13)/2)) \n",
    "print(k_neighbor(input_data=data, k=3, p=25)==((24+25+29)/3))\n",
    "print(k_neighbor(input_data=data, k=1, p=55)== 40)\n",
    "print(k_neighbor(input_data=data, k=3, p=55)==((25+29+40)/3))\n",
    "print(k_neighbor(input_data=data, k=10, p=55)==(np.mean([8,11,12,13,15,19,24,25,29,40])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n",
      "14.0\n",
      "26.0\n",
      "40.0\n",
      "31.333333333333332\n",
      "19.6\n"
     ]
    }
   ],
   "source": [
    "#Evaluate\n",
    "data = np.array([1,3,4,5,7,8,11,12,13,15,19,24,25,29,40])\n",
    "print(k_neighbor(input_data=data, k=3, p=5))\n",
    "print(k_neighbor(input_data=data, k=2, p=15))\n",
    "print(k_neighbor(input_data=data, k=3, p=25)) \n",
    "print(k_neighbor(input_data=data, k=1, p=55))\n",
    "print(k_neighbor(input_data=data, k=3, p=55))\n",
    "print(k_neighbor(input_data=data, k=10, p=55))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Enter your observations and comments here\n",
    "#tie breaking strategy should differ based on the use case\n",
    "#tried averaging results first by distance then taking the k nearest neighbour but this assumes \n",
    "#neighbours with varying distances are weighted the same\n",
    "#also this method would have an issue since >=k points from the dataset would be considered in the calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5. Similar to Q4 but for the n dimentional case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l1_norm(a,b):\n",
    "    #takes in array a and b and computes L1 norm\n",
    "    #Returns the l1 norm (a,b)\n",
    "    l1_norm = np.mean(np.sum(np.absolute(np.subtract(np.array(a),np.array(b)))))\n",
    "    return l1_norm\n",
    "\n",
    "def l2_norm(a,b):\n",
    "    \"\"\"Returns the l2 norm (a,b)\"\"\" \n",
    "    l2_norm = np.sqrt(np.sum(np.square(np.subtract(np.array(a),np.array(b)))))\n",
    "    return l2_norm\n",
    "            \n",
    "def k_neighbor_nd(input_data, k, p, metric='l1', mode='mean'):\n",
    "    \"\"\"Returns the k-neighbor estimate for p using data input_data.\n",
    "\n",
    "    Keyword arguments:\n",
    "    input_data -- numpy array of all the data\n",
    "    k -- Number of k\n",
    "    p -- input values\n",
    "    metric -- l1 or l2. l1 norm or l2 norm https://en.wikipedia.org/wiki/Norm_(mathematics)\n",
    "    mode -- estimator possible values = 'mean', 'median', 'max'\n",
    "    \n",
    "    Implement the l1 and l2 norms\n",
    "    for mean, median and max, use np.mean, np.median and np.max\n",
    "    \"\"\"\n",
    "    #Assuming the function returns a vector and not a scalar\n",
    "    \n",
    "    #YOUR CODE HERE\n",
    "    input_data_enhanced = pd.DataFrame(input_data)\n",
    "    if metric=='l2':\n",
    "        input_data_enhanced['dist'] = input_data_enhanced.apply(lambda row: l2_norm(row,p), axis=1)\n",
    "    elif metric=='l1':\n",
    "        input_data_enhanced['dist'] = input_data_enhanced.apply(lambda row: l1_norm(row,p), axis=1)\n",
    "    else:\n",
    "        print('wrong estimator selected')\n",
    "    #print(input_data_enhanced) #spot check\n",
    "    \n",
    "    #in case of ties: random - first instance selected\n",
    "    input_data_enhanced = input_data_enhanced.sort_values('dist',ascending = True)\n",
    "    #print(input_data_enhanced) #spot check\n",
    "    #getting the k neighbours\n",
    "    knn_value = input_data_enhanced[:k][input_data_enhanced.columns.difference(['dist'])]\n",
    "        \n",
    "    #return answer\n",
    "    return eval('np.array(knn_value.'+ mode+'())')\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.5 3.  0.5 1.5]\n"
     ]
    }
   ],
   "source": [
    "data_4d = np.array([[4, 1, 2, 1], [1, 4, 2, 0], [3, 3, 1, 1], \n",
    "        [4, 0, 0, 0], [1, 2, 0, 0], [3, 4, 2, 3], \n",
    "        [2, 4, 4, 2], [2, 1, 4, 1], [3, 3, 2, 4], \n",
    "        [4, 3, 0, 4], [2, 2, 4, 0],[4, 3, 0, 2], \n",
    "        [4, 3, 0, 2], [0, 3, 4, 2]])\n",
    "\n",
    "#print(k_neighbor_nd(input_data=data_4d, k=3, p=[2, 1, 4, 3], metric='l2', mode='mean'))\n",
    "print(k_neighbor_nd(input_data=data_4d, k=2, p=[4, 4, 0, 0], metric='l2', mode='mean'))\n",
    "\n",
    "#print(pd.DataFrame(data_4d).iloc[0,])\n",
    "#print(pd.DataFrame(np.array([[4, 1, 2, 1], [1, 4, 2, 0]])).values-pd.DataFrame(np.array([[2, 1, 4, 3]])).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.         2.33333333 4.         1.        ]\n",
      "[4. 3. 0. 2.]\n",
      "[4 4 2 4]\n",
      "[3. 3. 2. 4.]\n",
      "[3. 4. 2. 3.]\n",
      "[1.33333333 2.66666667 4.         1.66666667]\n",
      "[3.5 3.  0.5 1.5]\n",
      "[4 4 2 4]\n",
      "[3. 3. 2. 4.]\n",
      "[3. 4. 2. 3.]\n"
     ]
    }
   ],
   "source": [
    "#Evaluate\n",
    "print(k_neighbor_nd(input_data=data_4d, k=3, p=[2, 1, 4, 3], metric='l1', mode='mean'))\n",
    "print(k_neighbor_nd(input_data=data_4d, k=2, p=[4, 4, 0, 0], metric='l1', mode='mean'))\n",
    "print(k_neighbor_nd(input_data=data_4d, k=3, p=[2, 2, 2, 4], metric='l1', mode='max'))\n",
    "print(k_neighbor_nd(input_data=data_4d, k=1, p=[2, 3, 3, 4], metric='l1', mode='mean'))\n",
    "print(k_neighbor_nd(input_data=data_4d, k=3, p=[2, 3, 3, 4], metric='l1', mode='median'))\n",
    "print(k_neighbor_nd(input_data=data_4d, k=3, p=[2, 1, 4, 3], metric='l2', mode='mean'))\n",
    "print(k_neighbor_nd(input_data=data_4d, k=2, p=[4, 4, 0, 0], metric='l2', mode='mean'))\n",
    "print(k_neighbor_nd(input_data=data_4d, k=3, p=[2, 2, 2, 4], metric='l2', mode='max'))\n",
    "print(k_neighbor_nd(input_data=data_4d, k=1, p=[2, 3, 3, 4], metric='l2', mode='mean'))\n",
    "print(k_neighbor_nd(input_data=data_4d, k=3, p=[2, 3, 3, 4], metric='l2', mode='median'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Enter your observations and comments here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6[Optional]. Read the documentation on KNeighborsRegressor\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html\n",
    "    \n",
    "Explore the source code:\n",
    "    https://github.com/scikit-learn/scikit-learn/blob/ef5cb84a/sklearn/neighbors/regression.py\n",
    "        \n",
    "How different it is from your implementation? How well can you follow the code? Did you learn something new?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre> implementation is similar </pre>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
